============================= test session starts =============================
platform win32 -- Python 3.14.2, pytest-9.0.2, pluggy-1.6.0
rootdir: C:\Users\Craig\Corvus\CorvusStar
configfile: pyproject.toml
plugins: anyio-4.12.1
collected 208 items

tests\empire_tests\temp_gauntlet\test_annex_empire.py ....               [  1%]
tests\empire_tests\temp_gauntlet\test_dispatcher_empire.py ..            [  2%]
tests\empire_tests\temp_gauntlet\test_edda_empire.py ..                  [  3%]
tests\empire_tests\temp_gauntlet\test_engine_empire.py ....              [  5%]
tests\empire_tests\temp_gauntlet\test_fishtest_empire.py .......         [  9%]
tests\empire_tests\temp_gauntlet\test_harvest_empire.py F                [  9%]
tests\empire_tests\temp_gauntlet\test_install_skill_empire.py ...        [ 11%]
tests\empire_tests\temp_gauntlet\test_main_loop_empire.py ..             [ 12%]
tests\empire_tests\temp_gauntlet\test_personas_empire.py .....           [ 14%]
tests\empire_tests\temp_gauntlet\test_sanitizer_empire.py .......        [ 17%]
tests\empire_tests\temp_gauntlet\test_set_persona_empire.py ..           [ 18%]
tests\empire_tests\temp_gauntlet\test_skill_forge_empire.py ....         [ 20%]
tests\empire_tests\temp_gauntlet\test_sv_engine_empire.py ..             [ 21%]
tests\empire_tests\temp_gauntlet\test_temp_empire.py .                   [ 22%]
tests\empire_tests\temp_gauntlet\test_ui_empire.py ......                [ 25%]
tests\empire_tests\temp_gauntlet\test_utils_empire.py ...                [ 26%]
tests\empire_tests\test___init___empire.py .                             [ 26%]
tests\empire_tests\test_annex_empire.py .                                [ 27%]
tests\empire_tests\test_annex_preservation_empire.py .                   [ 27%]
tests\empire_tests\test_audit_dialogue_empire.py FF                      [ 28%]
tests\empire_tests\test_benchmark_engine_empire.py .                     [ 29%]
tests\empire_tests\test_bootstrap_empire.py FF                           [ 30%]
tests\empire_tests\test_catalog_check_empire.py ..                       [ 31%]
tests\empire_tests\test_check_pro_empire.py ..                           [ 32%]
tests\empire_tests\test_cjk_check_empire.py ..                           [ 33%]
tests\empire_tests\test_code_sanitizer_empire.py ....                    [ 35%]
tests\empire_tests\test_code_sentinel_empire.py ..                       [ 36%]
tests\empire_tests\test_collision_investigator_empire.py ...             [ 37%]
tests\empire_tests\test_compile_failure_report_empire.py .               [ 37%]
tests\empire_tests\test_compile_session_traces_empire.py ..              [ 38%]
tests\empire_tests\test_contextual_persona.py ...                        [ 40%]
tests\empire_tests\test_core_engine_empire.py .                          [ 40%]
tests\empire_tests\test_cstar_dispatcher_empire.py .                     [ 41%]
tests\empire_tests\test_daemon_singleton_empire.py ..                    [ 42%]
tests\empire_tests\test_debt_viz_empire.py ..                            [ 43%]
tests\empire_tests\test_debug_engine_empire.py ....                      [ 45%]
tests\empire_tests\test_dedupe_corrections_empire.py ..                  [ 46%]
tests\empire_tests\test_dispatcher_help_empire.py ..                     [ 47%]
tests\empire_tests\test_edda_audit_empire.py ...                         [ 48%]
tests\empire_tests\test_edda_empire.py .                                 [ 49%]
tests\empire_tests\test_edda_syntax_empire.py ..                         [ 50%]
tests\empire_tests\test_expand_thesaurus_empire.py ..                    [ 50%]
tests\empire_tests\test_fishtest_empire.py ..                            [ 51%]
tests\empire_tests\test_fix_muninn_empire.py .                           [ 52%]
tests\empire_tests\test_freya_aesthetics_empire.py ..                    [ 53%]
tests\empire_tests\test_generate_tests_empire.py .                       [ 53%]
tests\empire_tests\test_harvest_responses_empire.py ..                   [ 54%]
tests\empire_tests\test_hud_box_empire.py .                              [ 55%]
tests\empire_tests\test_install_skill_empire.py ..                       [ 56%]
tests\empire_tests\test_latency_check_empire.py ...                      [ 57%]
tests\empire_tests\test_lightning_rod_empire.py ..                       [ 58%]
tests\empire_tests\test_main_loop_empire.py ..                           [ 59%]
tests\empire_tests\test_merge_traces_empire.py ...                       [ 61%]
tests\empire_tests\test_metrics_empire.py ..                             [ 62%]
tests\empire_tests\test_migrate_to_qmd_empire.py ...                     [ 63%]
tests\empire_tests\test_muninn_empire.py .....                           [ 65%]
tests\empire_tests\test_muninn_memory_idempotency_empire.py .            [ 66%]
tests\empire_tests\test_muninn_naming_empire.py ..                       [ 67%]
tests\empire_tests\test_muninn_real_empire.py ...                        [ 68%]
tests\empire_tests\test_network_watcher_empire.py ..                     [ 69%]
tests\empire_tests\test_norn_campaign_empire.py ..                       [ 70%]
tests\empire_tests\test_overfit_corrections_empire.py .                  [ 71%]
tests\empire_tests\test_overwatch_empire.py ..                           [ 72%]
tests\empire_tests\test_persona_logic_empire.py .                        [ 72%]
tests\empire_tests\test_personas_empire.py .....                         [ 75%]
tests\empire_tests\test_personas_retheme_empire.py .                     [ 75%]
tests\empire_tests\test_prompt_linter_empire.py .....                    [ 77%]
tests\empire_tests\test_report_engine_empire.py ..                       [ 78%]
tests\empire_tests\test_runecaster_audit_empire.py ....                  [ 80%]
tests\empire_tests\test_scout_targets_empire.py .                        [ 81%]
tests\empire_tests\test_security_scan_empire.py ...                      [ 82%]
tests\empire_tests\test_sentinel_perf_empire.py ..                       [ 83%]
tests\empire_tests\test_set_persona_empire.py ....                       [ 85%]
tests\empire_tests\test_skill_forge_empire.py ...                        [ 87%]
tests\empire_tests\test_sv_engine_empire.py ...                          [ 88%]
tests\empire_tests\test_synapse_auth_empire.py ...                       [ 89%]
tests\empire_tests\test_synapse_sync_empire.py ..                        [ 90%]
tests\empire_tests\test_thewatcher_integrity_empire.py ...               [ 92%]
tests\empire_tests\test_trace_viz_empire.py ..                           [ 93%]
tests\empire_tests\test_tune_weights_empire.py ..                        [ 94%]
tests\empire_tests\test_ui_empire.py ....F                               [ 96%]
tests\empire_tests\test_update_gemini_manifest_empire.py .               [ 97%]
tests\empire_tests\test_utils_empire.py ...                              [ 98%]
tests\empire_tests\test_valkyrie_audit_empire.py ..                      [ 99%]
tests\empire_tests\test_verify_valkyrie_real_empire.py .                 [100%]

================================== FAILURES ===================================
_____________________ TestHarvestEmpire.test_harvest_loop _____________________

args = (<temp_gauntlet.test_harvest_empire.TestHarvestEmpire object at 0x000001D940F55950>,)
keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python314\Lib\unittest\mock.py:1429: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python314\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
C:\Python314\Lib\unittest\mock.py:1411: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python314\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
C:\Python314\Lib\unittest\mock.py:1487: in __enter__
    self.target = self.getter()
                  ^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

name = 'src.sentinel.harvest_responses.genai'

    def resolve_name(name):
        """
        Resolve a name to an object.
    
        It is expected that `name` will be a string in one of the following
        formats, where W is shorthand for a valid Python identifier and dot stands
        for a literal period in these pseudo-regexes:
    
        W(.W)*
        W(.W)*:(W(.W)*)?
    
        The first form is intended for backward compatibility only. It assumes that
        some part of the dotted name is a package, and the rest is an object
        somewhere within that package, possibly nested inside other objects.
        Because the place where the package stops and the object hierarchy starts
        can't be inferred by inspection, repeated attempts to import must be done
        with this form.
    
        In the second form, the caller makes the division point clear through the
        provision of a single colon: the dotted name to the left of the colon is a
        package to be imported, and the dotted name to the right is the object
        hierarchy within that package. Only one import is needed in this form. If
        it ends with the colon, then a module object is returned.
    
        The function will return an object (which might be a module), or raise one
        of the following exceptions:
    
        ValueError - if `name` isn't in a recognised format
        ImportError - if an import failed when it shouldn't have
        AttributeError - if a failure occurred when traversing the object hierarchy
                         within the imported package to get to the desired object.
        """
        global _NAME_PATTERN
        if _NAME_PATTERN is None:
            # Lazy import to speedup Python startup time
            import re
            dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'
                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',
                                       re.UNICODE)
    
        m = _NAME_PATTERN.match(name)
        if not m:
            raise ValueError(f'invalid format: {name!r}')
        gd = m.groupdict()
        if gd.get('cln'):
            # there is a colon - a one-step import is all that's needed
            mod = importlib.import_module(gd['pkg'])
            parts = gd.get('obj')
            parts = parts.split('.') if parts else []
        else:
            # no colon - have to iterate to find the package boundary
            parts = name.split('.')
            modname = parts.pop(0)
            # first part *must* be a module/package.
            mod = importlib.import_module(modname)
            while parts:
                p = parts[0]
                s = f'{modname}.{p}'
                try:
                    mod = importlib.import_module(s)
                    parts.pop(0)
                    modname = s
                except ImportError:
                    break
        # if we reach this point, mod is the module, already imported, and
        # parts is the list of parts in the object hierarchy to be traversed, or
        # an empty list if just the module is wanted.
        result = mod
        for p in parts:
>           result = getattr(result, p)
                     ^^^^^^^^^^^^^^^^^^
E           AttributeError: module 'src.sentinel.harvest_responses' has no attribute 'genai'

C:\Python314\Lib\pkgutil.py:473: AttributeError
___________________ TestAuditDialogueEmpire.test_audit_flow ___________________

self = <test_audit_dialogue_empire.TestAuditDialogueEmpire object at 0x000001D941022850>
mock_dialogue = <MagicMock name='DialogueEngine' id='2032615794608'>
mock_hud = <MagicMock name='HUD' id='2032615794944'>
mock_sv_cls = <MagicMock name='SovereignEngine' id='2032615795280'>

    @patch("src.tools.debug.audit_dialogue.sv_engine.SovereignEngine")
    @patch("src.tools.debug.audit_dialogue.sv_engine.HUD")
    @patch("src.tools.debug.audit_dialogue.sv_engine.DialogueEngine")
    def test_audit_flow(self, mock_dialogue, mock_hud, mock_sv_cls):
        mock_engine = mock_sv_cls.return_value
        mock_engine.score_identity.return_value = 0.9
    
        auditor = audit_dialogue.DialogueAuditor()
>       auditor.audit("test dialogue")

tests\empire_tests\test_audit_dialogue_empire.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\tools\debug\audit_dialogue.py:63: in audit
    score = self.engine.score_identity(text, self.persona)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.core.engine.vector.SovereignVector object at 0x000001D9412C2190>
text = 'test dialogue', persona_name = 'ALFRED'

    def score_identity(self, text: str, persona_name: str) -> float:
        """
        Calculates a 'Purity Score' (0-1) by comparing input text
        to the vector space of the chosen persona's dialogue.
        """
        # 1. Expand query for text
        weighted_tokens = self.expand_query(text)
        text_vec = self._vectorize(weighted_tokens)
    
        # 2. Re-index temporarily on dialogue
        # We need a mini-engine for this or just simulate similarity
        # Let's use the current engine's vocab but check against dialogue data
        # If the text has tokens that appear frequently in the persona's DB, it's a match.
    
        # Actually, if we have HUD.DIALOGUE loaded, we can compare directly.
        # Simple heuristic for now: token overlap with dialogue registry
        tokens = set(self.tokenize(text))
        persona_tokens = set()
    
        # Defensive check for HUD.DIALOGUE
        if HUD.DIALOGUE:
>           for phrases in HUD.DIALOGUE.intents.values():
                           ^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'DialogueEngine' object has no attribute 'intents'

src\core\engine\vector.py:491: AttributeError
---------------------------- Captured stdout call -----------------------------
[2;36m???????????????????????????????????????? [36m[1mENGINE INITIALIZED[0m[2;36m ????????????????????????????????????????[0m
[2;36m?[0m [36mSTATUS              [0m [32mONLINE[0m                                                                       [2;36m?[0m
[2;36m????????????????????????????????????????????????????????????????????????????????????????????????????[0m
_________________ TestAuditDialogueEmpire.test_audit_deviance _________________

self = <test_audit_dialogue_empire.TestAuditDialogueEmpire object at 0x000001D941022990>
mock_dialogue = <MagicMock name='DialogueEngine' id='2032615797632'>
mock_hud = <MagicMock name='HUD' id='2032615797296'>
mock_sv_cls = <MagicMock name='SovereignEngine' id='2032615797968'>

    @patch("src.tools.debug.audit_dialogue.sv_engine.SovereignEngine")
    @patch("src.tools.debug.audit_dialogue.sv_engine.HUD")
    @patch("src.tools.debug.audit_dialogue.sv_engine.DialogueEngine")
    def test_audit_deviance(self, mock_dialogue, mock_hud, mock_sv_cls):
        mock_engine = mock_sv_cls.return_value
        mock_engine.score_identity.return_value = 0.3
    
        auditor = audit_dialogue.DialogueAuditor()
>       auditor.audit("deviant dialogue")

tests\empire_tests\test_audit_dialogue_empire.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\tools\debug\audit_dialogue.py:63: in audit
    score = self.engine.score_identity(text, self.persona)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.core.engine.vector.SovereignVector object at 0x000001D9412C28B0>
text = 'deviant dialogue', persona_name = 'ALFRED'

    def score_identity(self, text: str, persona_name: str) -> float:
        """
        Calculates a 'Purity Score' (0-1) by comparing input text
        to the vector space of the chosen persona's dialogue.
        """
        # 1. Expand query for text
        weighted_tokens = self.expand_query(text)
        text_vec = self._vectorize(weighted_tokens)
    
        # 2. Re-index temporarily on dialogue
        # We need a mini-engine for this or just simulate similarity
        # Let's use the current engine's vocab but check against dialogue data
        # If the text has tokens that appear frequently in the persona's DB, it's a match.
    
        # Actually, if we have HUD.DIALOGUE loaded, we can compare directly.
        # Simple heuristic for now: token overlap with dialogue registry
        tokens = set(self.tokenize(text))
        persona_tokens = set()
    
        # Defensive check for HUD.DIALOGUE
        if HUD.DIALOGUE:
>           for phrases in HUD.DIALOGUE.intents.values():
                           ^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'DialogueEngine' object has no attribute 'intents'

src\core\engine\vector.py:491: AttributeError
---------------------------- Captured stdout call -----------------------------
[2;36m???????????????????????????????????????? [36m[1mENGINE INITIALIZED[0m[2;36m ????????????????????????????????????????[0m
[2;36m?[0m [36mSTATUS              [0m [32mONLINE[0m                                                                       [2;36m?[0m
[2;36m????????????????????????????????????????????????????????????????????????????????????????????????????[0m
___________________ TestBootstrapEmpire.test_bootstrap_flow ___________________

args = (<test_bootstrap_empire.TestBootstrapEmpire object at 0x000001D941023ED0>,)
keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python314\Lib\unittest\mock.py:1429: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python314\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
C:\Python314\Lib\unittest\mock.py:1411: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python314\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
C:\Python314\Lib\unittest\mock.py:1503: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001D9410DA0B0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.sentinel._bootstrap' from 'C:\\Users\\Craig\\Corvus\\CorvusStar\\src\\sentinel\\_bootstrap.py'> does not have the attribute 'HUD'

C:\Python314\Lib\unittest\mock.py:1473: AttributeError
_______________ TestBootstrapEmpire.test_bootstrap_no_env_file ________________

self = <test_bootstrap_empire.TestBootstrapEmpire object at 0x000001D941023110>
mock_dotenv = <MagicMock name='load_dotenv' id='2032612309184'>

    @patch("src.sentinel._bootstrap.load_dotenv", create=True)
    def test_bootstrap_no_env_file(self, mock_dotenv):
        _bootstrap._BOOTSTRAPPED = False
>       with patch("src.sentinel._bootstrap.HUD"), \
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch("src.sentinel._bootstrap.load_config", return_value={}, create=True):

tests\empire_tests\test_bootstrap_empire.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python314\Lib\unittest\mock.py:1503: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001D9412AF070>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.sentinel._bootstrap' from 'C:\\Users\\Craig\\Corvus\\CorvusStar\\src\\sentinel\\_bootstrap.py'> does not have the attribute 'HUD'

C:\Python314\Lib\unittest\mock.py:1473: AttributeError
_______________________ TestUIEmpire.test_log_rejection _______________________

self = <test_ui_empire.TestUIEmpire object at 0x000001D9411B3770>
mock_file = <MagicMock name='open' id='2032642440704'>
mock_cwd = <MagicMock name='cwd' id='2032642984992'>

    @patch("src.core.ui.Path.cwd")
    @patch("src.core.ui.Path.open", new_callable=mock_open)
    def test_log_rejection(self, mock_file, mock_cwd):
        # setup deep path mock for ledger
        mock_path = MagicMock()
        mock_cwd.return_value = mock_path
    
        # HUD.log_rejection uses Path.cwd() / ".agent" / "audit" / "ledger.json"
        HUD.log_rejection("TEST_PERSONA", "Reason", "Details")
    
        # Verify it attempted to open a file
>       mock_file.assert_called()

tests\empire_tests\test_ui_empire.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <MagicMock name='open' id='2032642440704'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'open' to have been called.

C:\Python314\Lib\unittest\mock.py:954: AssertionError
============================== warnings summary ===============================
..\..\AppData\Roaming\Python\Python314\site-packages\google\genai\types.py:43
  C:\Users\Craig\AppData\Roaming\Python\Python314\site-packages\google\genai\types.py:43: DeprecationWarning: '_UnionGenericAlias' is deprecated and slated for removal in Python 3.17
    VersionedUnionType = Union[builtin_types.UnionType, _UnionGenericAlias]

tests/empire_tests/test_sv_engine_empire.py::TestSovereignEngineEmpire::test_run_basic_flow
  C:\Users\Craig\AppData\Roaming\Python\Python314\site-packages\_pytest\threadexception.py:58: PytestUnhandledThreadExceptionWarning: Exception in thread Thread-21 (_read)
  
  Traceback (most recent call last):
    File "C:\Python314\Lib\threading.py", line 1082, in _bootstrap_inner
      self._context.run(self.run)
      ~~~~~~~~~~~~~~~~~^^^^^^^^^^
    File "C:\Python314\Lib\threading.py", line 1024, in run
      self._target(*self._args, **self._kwargs)
      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "C:\Users\Craig\Corvus\CorvusStar\src\core\utils.py", line 54, in _read
      try: q.put(sys.stdin.readline().strip().lower())
                 ~~~~~~~~~~~~~~~~~~^^
    File "C:\Users\Craig\AppData\Roaming\Python\Python314\site-packages\_pytest\capture.py", line 229, in read
      raise OSError(
          "pytest: reading from stdin while output is captured!  Consider using `-s`."
      )
  OSError: pytest: reading from stdin while output is captured!  Consider using `-s`.
  
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.
    warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/empire_tests/temp_gauntlet/test_harvest_empire.py::TestHarvestEmpire::test_harvest_loop
FAILED tests/empire_tests/test_audit_dialogue_empire.py::TestAuditDialogueEmpire::test_audit_flow
FAILED tests/empire_tests/test_audit_dialogue_empire.py::TestAuditDialogueEmpire::test_audit_deviance
FAILED tests/empire_tests/test_bootstrap_empire.py::TestBootstrapEmpire::test_bootstrap_flow
FAILED tests/empire_tests/test_bootstrap_empire.py::TestBootstrapEmpire::test_bootstrap_no_env_file
FAILED tests/empire_tests/test_ui_empire.py::TestUIEmpire::test_log_rejection
================= 6 failed, 202 passed, 2 warnings in 37.65s ==================
